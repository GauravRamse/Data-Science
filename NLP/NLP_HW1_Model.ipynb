{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3WhkazVxExC"
      },
      "outputs": [],
      "source": [
        "# !pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing liabraries"
      ],
      "metadata": {
        "id": "lV5emUfvvIyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC2pN0WRahDI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULqRJ0yaFCl8"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = r\"/content/drive/MyDrive/Sem_4/NLP_HW_1/nlp2022-hw1-main\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ZFElkBXqTp"
      },
      "outputs": [],
      "source": [
        "def get_Text(lines, count):\n",
        "    count = count\n",
        "    initial_char = lines[count]\n",
        "    Text = []\n",
        "    Text.append(initial_char.strip().split(\"\\t\"))\n",
        "\n",
        "    count +=1\n",
        "    initial_char = lines[count]\n",
        "\n",
        "    while initial_char.startswith(\"#\") == False:\n",
        "        count +=1\n",
        "        Text.append(initial_char.strip().split(\"\\t\"))\n",
        "        initial_char = lines[count]\n",
        "    return Text, count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmrtAWPfCpih"
      },
      "outputs": [],
      "source": [
        "def get_df(filename , type_of_data) :  \n",
        "    f = open(os.path.join(BASE_PATH, f\"data/{filename}\"))\n",
        "    lines = f.readlines()\n",
        "    length_of_file = len(lines)\n",
        "    if type_of_data == \"train\":\n",
        "        Text = []\n",
        "        Tag = []\n",
        "        Id = []\n",
        "        count = 0\n",
        "        while count < length_of_file:\n",
        "            try :\n",
        "                text, count = get_Text(lines, count)\n",
        "                Id.append(int(text[0][-1]))\n",
        "                Text.append([i[0] for i in text[1:-1]])\n",
        "                Tag.append([i[1] for i in text[1:-1]])\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        df = pd.DataFrame(columns = [\"Id\", \"Tag\", \"Text\"])\n",
        "        df[\"Id\"]  = Id\n",
        "        df[\"Tag\"] = Tag\n",
        "        df[\"Text\"] = Text\n",
        "    elif type_of_data == \"test\":\n",
        "        Text = []\n",
        "        Id = []\n",
        "        count = 0\n",
        "        while count < length_of_file:\n",
        "            try :\n",
        "                text, count = get_Text(lines, count)\n",
        "                Id.append(int(text[0][-1]))\n",
        "                Text.append([i[0] for i in text[1:-1]])\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        df = pd.DataFrame(columns = [\"Id\", \"Text\"])\n",
        "        df[\"Id\"]  = Id\n",
        "        df[\"Text\"] = Text\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IzxElalGIw1"
      },
      "outputs": [],
      "source": [
        "filename = \"train.tsv\"\n",
        "df_train = get_df(\"train.tsv\",  \"train\")\n",
        "df_dev = get_df(\"dev.tsv\",  \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qGHkbz22X9S-",
        "outputId": "37fa54df-59e8-40dd-c728-6863e66f5e7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id                                                Tag  \\\n",
              "0   0  [O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O,...   \n",
              "1   1  [B-CW, I-CW, I-CW, I-CW, I-CW, I-CW, I-CW, I-C...   \n",
              "2   2  [B-PER, I-PER, O, B-PER, I-PER, O, B-PER, I-PE...   \n",
              "3   3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "4   4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "\n",
              "                                                Text  \n",
              "0  [it, lies, approximately, north, east, of, bol...  \n",
              "1  [does, anybody, really, know, what, time, it, ...  \n",
              "2  [amrish, puri, ,, anupam, kher, ,, mukesh, kha...  \n",
              "3  [wilds, himself, later, said, that, he, was, c...  \n",
              "4  [he, scored, the, first, goal, of, a, famous, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68871eaf-49d2-4f7e-a1dd-1280c9ddb899\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[it, lies, approximately, north, east, of, bol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[B-CW, I-CW, I-CW, I-CW, I-CW, I-CW, I-CW, I-C...</td>\n",
              "      <td>[does, anybody, really, know, what, time, it, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[B-PER, I-PER, O, B-PER, I-PER, O, B-PER, I-PE...</td>\n",
              "      <td>[amrish, puri, ,, anupam, kher, ,, mukesh, kha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[wilds, himself, later, said, that, he, was, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[he, scored, the, first, goal, of, a, famous, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68871eaf-49d2-4f7e-a1dd-1280c9ddb899')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68871eaf-49d2-4f7e-a1dd-1280c9ddb899 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68871eaf-49d2-4f7e-a1dd-1280c9ddb899');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Nel-LGOQjTjJ",
        "outputId": "b1ef0e87-e67a-4277-c54c-8226a2c2602c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf19c00810>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df_train[\"Text\"].map(len).plot(kind = \"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ8Ag5-4DXP5"
      },
      "outputs": [],
      "source": [
        "def get_vocab(Text: list ):\n",
        "    vocab = []\n",
        "    for sentence in tqdm(Text):\n",
        "        for word in sentence:\n",
        "            vocab.append(word)\n",
        "    vocab = Counter(vocab)\n",
        "    return vocab\n",
        "\n",
        "def word_to_id(vocab, unknown):\n",
        "    word_to_id_dict = {}\n",
        "    \n",
        "    count = 0\n",
        "    for word in vocab:\n",
        "        word_to_id_dict[word] = count\n",
        "        count = count +1\n",
        "    word_to_id_dict[unknown] = count\n",
        "    return word_to_id_dict\n",
        "\n",
        "vocab_word_count_dict = get_vocab(df_train[\"Text\"].to_list())\n",
        "vocab = list(set(list(vocab_word_count_dict.keys())))\n",
        "\n",
        "# tag_count_dict = get_vocab(df_train[\"Tag\"].to_list())\n",
        "# tag = list(set(list(tag_count_dict.keys())))\n",
        "\n",
        "unknown_word = \"<UNK>\"\n",
        "# unknown_tag = \"<UNK_Tag>\"\n",
        "\n",
        "word_to_id_dict = word_to_id(vocab, unknown_word)\n",
        "id_to_word_dict = dict((value, key)  for key , value in word_to_id_dict.items())\n",
        "\n",
        "# tag_to_id_dict = word_to_id(tag, unknown_tag)\n",
        "# id_to_tag_dict = dict((value, key)  for key , value in tag_to_id_dict.items())\n",
        "\n",
        "\n",
        "# tag_to_ix = word_to_id(tag, unknown_tag)\n",
        "word_to_ix = word_to_id(vocab, unknown_word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# with open(BASE_PATH + \"/data/word_to_ix.json\", \"w\", encoding ='utf8') as f:\n",
        "#     json.dump(word_to_ix, f)"
      ],
      "metadata": {
        "id": "fGkk_dMLtIFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(BASE_PATH + \"/data/word_to_ix.json\", \"r\", encoding ='utf8') as f:\n",
        "    word_to_ix = json.load(f)\n",
        "\n",
        "with open(BASE_PATH + \"/data/tag_to_ix.json\", \"r\", encoding ='utf8') as f:\n",
        "    tag_to_ix = json.load(f)"
      ],
      "metadata": {
        "id": "_l-jfOqF3T-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgkLS6GuY-vF"
      },
      "outputs": [],
      "source": [
        "# class_weights = compute_class_weight(class_weight=\"balanced\", classes= list(tag_to_ix.keys()), y=[j for i in df_train[\"Tag\"] for j in i ])\n",
        "# np.savetxt(BASE_PATH + \"/data/class_weights.txt\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights  = np.loadtxt(BASE_PATH + \"/data/class_weights.txt\")\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCDcvPm7uwlL",
        "outputId": "692138bc-8c2b-4e52-caf8-259fea4d3fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6.20664512,  5.20134345,  5.47104274,  4.05284663,  3.62765604,\n",
              "        6.66598167,  6.18171049,  3.23036551,  3.03497193,  7.10730147,\n",
              "        3.1808388 , 10.79811066,  0.09575871])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6wJnYTMSAg5"
      },
      "source": [
        "### Model 1- Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg_geA3Ro5pP"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "for i in range(len(df_train)):\n",
        "    row = df_train.iloc[i]\n",
        "    training_data.append((row[\"Text\"], row[\"Tag\"]))\n",
        "\n",
        "dev_data = []\n",
        "for i in range(len(df_dev)):\n",
        "    row = df_dev.iloc[i]\n",
        "    dev_data.append((row[\"Text\"], row[\"Tag\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4sYaQ7-o5u_"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVkqfmN2o8P-"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,  num_layers= 2, dropout=0.2)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkCixlvVygJG"
      },
      "outputs": [],
      "source": [
        "torch.Tensor(class_weights).to(device)\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix)).to(device)\n",
        "loss_function = nn.NLLLoss(weight = torch.Tensor(class_weights).to(device))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_599Azzo8NV",
        "outputId": "ac89cc5f-9470-4f93-dc85-ad1d3f1ff8ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14534/14534 [01:43<00:00, 139.88it/s]\n",
            "100%|██████████| 14534/14534 [01:31<00:00, 159.32it/s]\n",
            "100%|██████████| 14534/14534 [01:31<00:00, 159.14it/s]\n",
            "100%|██████████| 14534/14534 [01:40<00:00, 144.21it/s]\n",
            "100%|██████████| 14534/14534 [01:33<00:00, 154.82it/s]\n"
          ]
        }
      ],
      "source": [
        "Lossses_list =[]\n",
        "for epoch in range(5):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    for sentence, tags in tqdm(training_data):\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "        \n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "        # Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "        sentence_in =sentence_in.to(device)\n",
        "        targets =targets.to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        \n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        #  calling optimizer.step()\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        Lossses_list.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0pmr1S0gLCF",
        "outputId": "38de3a32-6c93-4e52-fa5b-24e89cb01bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-CORP       0.54      0.48      0.51       119\n",
            "        B-CW       0.22      0.34      0.26       133\n",
            "       B-GRP       0.78      0.59      0.67       376\n",
            "       B-LOC       0.36      0.23      0.28       149\n",
            "       B-PER       0.66      0.31      0.42       189\n",
            "      B-PROD       0.62      0.75      0.68       329\n",
            "      I-CORP       0.51      0.59      0.55       243\n",
            "        I-CW       0.21      0.04      0.06       170\n",
            "       I-GRP       0.70      0.33      0.45       153\n",
            "       I-LOC       0.91      0.97      0.94     10230\n",
            "       I-PER       0.26      0.24      0.25       261\n",
            "      I-PROD       0.50      0.49      0.50        87\n",
            "           O       0.89      0.08      0.15       300\n",
            "\n",
            "    accuracy                           0.86     12739\n",
            "   macro avg       0.55      0.42      0.44     12739\n",
            "weighted avg       0.85      0.86      0.84     12739\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def predict(indices):    \n",
        "    for index in range(len(indices)):\n",
        "        with torch.no_grad():\n",
        "            inputs = prepare_sequence(dev_data[index][0], word_to_ix)\n",
        "            inputs = inputs.to(device)\n",
        "            tag_scores = model(inputs)\n",
        "        values, target = torch.max(tag_scores, 1)\n",
        "        target = np.array(target.to('cpu'))\n",
        "        yield target\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "    y_pred = np.concatenate(tuple(y_pred))\n",
        "    y_true = np.concatenate(tuple([[t for t in y] for y in y_true])).reshape(y_pred.shape)\n",
        "    return (y_true == y_pred).sum() / float(len(y_true))\n",
        "\n",
        "y_pred = list(predict([s for s, t in dev_data]))\n",
        "y_true = [t for s, t in dev_data]\n",
        "\n",
        "y_true_indexed = []\n",
        "for tag in y_true:\n",
        "    tag_lst=[]\n",
        "    for i in tag:\n",
        "        tag_lst.append(tag_to_ix[i])\n",
        "\n",
        "    y_true_indexed.append(tag_lst)\n",
        "y_true = y_true_indexed\n",
        "\n",
        "tag_lst=[]\n",
        "for tag in y_true:\n",
        "\n",
        "    for i in tag:\n",
        "        tag_lst.append(i)\n",
        "\n",
        "tag_lst_pred=[]\n",
        "for tag in y_pred:\n",
        "\n",
        "    for i in tag:\n",
        "        tag_lst_pred.append(i)\n",
        "\n",
        "report = classification_report(tag_lst, tag_lst_pred, target_names=tag_to_ix.keys())\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "aPse397OgsoV",
        "outputId": "4a91b6dc-d4f7-4f81-a661-32968f7c6731"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"bedc867f-763e-462f-bc09-1318390de97a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bedc867f-763e-462f-bc09-1318390de97a\")) {                    Plotly.newPlot(                        \"bedc867f-763e-462f-bc09-1318390de97a\",                        [{\"hovertemplate\":\"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4],\"xaxis\":\"x\",\"y\":[2.753222703933716,0.19363178312778473,0.064907968044281,0.044153500348329544,0.1290157437324524],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Life expectancy in Canada\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bedc867f-763e-462f-bc09-1318390de97a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "l = [i.detach().to(\"cpu\").numpy() for i in Lossses_list]\n",
        "z = []\n",
        "for i in range(5):\n",
        "    z.append(l[i*14534])\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(z ,title='Losses with epochs')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu6DBgAUhXiw"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Sem_4/NLP_HW_1/nlp2022-hw1-main/model_1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_HrFe3qM9_N"
      },
      "source": [
        "### Functions for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1up8g_WORsYq",
        "outputId": "30ee0c53-54f6-4c0f-efd8-090956a278ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-09 21:41:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-09 21:41:59--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/drive/MyDrive/Sem_4/glove_model/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 40s  \n",
            "\n",
            "2022-04-09 21:44:39 (5.13 MB/s) - ‘/content/drive/MyDrive/Sem_4/glove_model/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/drive/MyDrive/Sem_4/glove_model/glove.6B.zip\n",
            "  inflating: /content/drive/MyDrive/Sem_4/glove_model/glove.6B.50d.txt  \n",
            "  inflating: /content/drive/MyDrive/Sem_4/glove_model/glove.6B.100d.txt  \n",
            "  inflating: /content/drive/MyDrive/Sem_4/glove_model/glove.6B.200d.txt  \n",
            "  inflating: /content/drive/MyDrive/Sem_4/glove_model/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "# !wget https://nlp.stanford.edu/data/glove.6B.zip -P /content/drive/MyDrive/Sem_4/glove_model/\n",
        "# !unzip /content/drive/MyDrive/Sem_4/glove_model/glove*.zip -d /content/drive/MyDrive/Sem_4/glove_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2jcHhkhy1pD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc2YuGLYRsVt"
      },
      "outputs": [],
      "source": [
        "# Let's read file, to understand word embedding\n",
        "def get_embedding_dict(embedding_path):\n",
        "    embedding_vectot_dict= {}\n",
        "    with open(os.path.join(\"/content/drive/MyDrive/Sem_4/\", embedding_path),\"r\", encoding= \"utf8\") as f:\n",
        "        for line in tqdm(f.readlines()):\n",
        "            word, *vector = line.split()\n",
        "            embedding_vectot_dict[word] = np.array(vector, \"float32\")\n",
        "    return embedding_vectot_dict\n",
        "\n",
        "def get_embedding_matrix(embedding_path_50):\n",
        "    embedding_dict = get_embedding_dict(embedding_path_50)\n",
        "    embedding_matrix = []\n",
        "    for idx, word in enumerate(word_to_ix.keys()):\n",
        "        try :\n",
        "            embedding_matrix.append(embedding_dict[word])  \n",
        "        except:\n",
        "            embedding_matrix.append(np.random.normal(scale=0.5, size=(EMBEDDING_DIM, )).tolist())\n",
        "    embedding_matrix = np.array(embedding_matrix)\n",
        "    return embedding_matrix\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = []\n",
        "    for w in seq:\n",
        "        try:\n",
        "            idxs.append(to_ix[w])\n",
        "        except:\n",
        "            idxs.append(to_ix[unknown_word])\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def get_flatten_tensor_to_calculate_loss(tag_scores, target):\n",
        "    mask = target>=0\n",
        "    mask = mask.to(device)\n",
        "    tag_scores = tag_scores.view(-1,13)[ mask.view(-1)]\n",
        "\n",
        "    actual_target = target.view(-1,1)[ mask.view(-1,1)]\n",
        "    one_hot_encod_class = torch.nn.functional.one_hot(actual_target, 13).to(device)\n",
        "    return  tag_scores, one_hot_encod_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61C2oVVhSxZJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, training_data, word_to_ix, tag_to_ix):\n",
        "        self.training_data = training_data\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.training_data[idx]\n",
        "        sentence= data[0]\n",
        "        tags=  data[1]\n",
        "        sentence_in = prepare_sequence(sentence, self.word_to_ix)\n",
        "        targets = prepare_sequence(tags, self.tag_to_ix)\n",
        "\n",
        "        return sentence_in, targets\n",
        "\n",
        "def get_actual_and_prediction(tag_scores,  target):\n",
        "    mask = target>=0\n",
        "    mask = mask.to(device)\n",
        "    tag_scores = tag_scores.view(-1,13)[ mask.view(-1)]\n",
        "    actual_target = target.view(-1,1)[ mask.view(-1,1)]\n",
        "    prediction = tag_scores.max(1)[1]\n",
        "    actual_target.to(device)\n",
        "\n",
        "    return prediction, actual_target\n",
        "    \n",
        "def get_model_prediction_actual(dataset_ds):\n",
        "    prediction_list = []\n",
        "    actual_list = [] \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for ii in dataset_ds: \n",
        "    \n",
        "            sentence_in = ii[0]\n",
        "            target = ii[1]\n",
        "\n",
        "            sentence_in = pad_sequence(sentence_in, batch_first=True, padding_value=word_to_ix[\"<UNK>\"])\n",
        "            target = pad_sequence(target, batch_first=True, padding_value=-1)\n",
        "\n",
        "            sentence_in = sentence_in.to(device)\n",
        "            target_label = target.to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            tag_scores = model(sentence_in)\n",
        "\n",
        "            prediction, actual_target = get_actual_and_prediction(tag_scores,  target_label)\n",
        "            prediction = np.array(prediction.to(\"cpu\"))\n",
        "            actual_target = np.array(actual_target.to(\"cpu\"))\n",
        "\n",
        "            for p, a in zip(prediction, actual_target):\n",
        "                prediction_list.append(p)\n",
        "                actual_list.append(a) \n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    return prediction_list, actual_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSX_oBa9PSK9"
      },
      "outputs": [],
      "source": [
        "def calculate_F1_Score(dataset):\n",
        "    prediction_list, actual_list = get_model_prediction_actual(dataset)\n",
        "    report = classification_report(actual_list, prediction_list, target_names=tag_to_ix.keys(),output_dict=True)\n",
        "    return format(report[\"macro avg\"][\"f1-score\"], \".4f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXpoqmOZNCxd"
      },
      "source": [
        "## Model 2- With dice loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPbV0PNc8Alx"
      },
      "outputs": [],
      "source": [
        "training_data = []\n",
        "for i in range(len(df_train)):\n",
        "    row = df_train.iloc[i]\n",
        "    training_data.append((row[\"Text\"], row[\"Tag\"]))\n",
        "\n",
        "dev_data = []\n",
        "for i in range(len(df_dev)):\n",
        "    row = df_dev.iloc[i]\n",
        "    dev_data.append((row[\"Text\"], row[\"Tag\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoLCZxQAMw9K",
        "outputId": "214074a6-6305-47d9-a209-75d2da9d0531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400000/400000 [00:31<00:00, 12734.03it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# EMBEDDING_DIM = 300\n",
        "# embedding_path_50 = f\"glove_model/glove.6B.{EMBEDDING_DIM}d.txt\"\n",
        "# embedding_matrix = get_embedding_matrix(embedding_path_50)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savetxt(BASE_PATH + \"/data/embedding_matrix.txt\", embedding_matrix)\n",
        "\n",
        "embedding_matrix = np.loadtxt(BASE_PATH + \"/data/embedding_matrix.txt\")"
      ],
      "metadata": {
        "id": "_nTEgSM5shAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHjdnfOQRMse"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, embedding_matrix, dense_layer_neurons):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "       \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.word_embeddings.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.word_embeddings.requires_grad_ = False\n",
        "        \n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,  num_layers=2, dropout = 0.1, bidirectional = True , batch_first = True)\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "\n",
        "        # self.dense = nn.Linear(2*hidden_dim, dense_layer_neurons)\n",
        "\n",
        "        # self.hidden2tag = nn.Linear( dense_layer_neurons, tagset_size)\n",
        "\n",
        "        self.hidden2tag = nn.Linear( 2*hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        # dense = self.dense(lstm_out)\n",
        "        # tag_space = self.hidden2tag(dense)\n",
        "\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights = torch.Tensor(class_weights).to(device)"
      ],
      "metadata": {
        "id": "fFl93Apxk9aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btp6z2z1QR6G"
      },
      "outputs": [],
      "source": [
        "hyper_parameters = {\"EMBEDDING_DIM\":300, \n",
        "                    \"HIDDEN_DIM\" :    400,\n",
        "                    \"BATCH_SIZE\" :    32,\n",
        "                    \"dense_layer_neurons\" : 26,\n",
        "                    \"learning_rate\":0.001, \"num_layers\":2, \"dropout\" : 0.2, \"epochs\" :70} \n",
        "\n",
        "EMBEDDING_DIM = hyper_parameters[\"EMBEDDING_DIM\"]\n",
        "HIDDEN_DIM = hyper_parameters[\"HIDDEN_DIM\"]\n",
        "batch_size = hyper_parameters[\"BATCH_SIZE\"]\n",
        "dense_layer_neurons = hyper_parameters[\"dense_layer_neurons\"]\n",
        "learning_rate = hyper_parameters[\"learning_rate\"]\n",
        "num_layers = hyper_parameters[\"num_layers\"]\n",
        "dropout =  hyper_parameters[\"dropout\"]\n",
        "epochs = hyper_parameters[\"epochs\"]\n",
        "\n",
        "import json\n",
        "with open(BASE_PATH + \"/hyperparameters.json\", \"+a\", encoding ='utf8') as f:\n",
        "    json.dump(hyper_parameters, f)\n",
        "\n",
        "# class_weights = torch.Tensor(class_weights).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3oyz12kE7KbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqTSsX78RMvs"
      },
      "outputs": [],
      "source": [
        "train_ds_custom = CustomImageDataset(training_data, word_to_ix, tag_to_ix)\n",
        "train_ds = DataLoader(train_ds_custom, batch_size=batch_size, shuffle=True, collate_fn=lambda x: list(zip(*x)) )\n",
        "\n",
        "dev_ds_custom = CustomImageDataset(dev_data, word_to_ix, tag_to_ix)\n",
        "dev_ds = DataLoader(dev_ds_custom, batch_size=batch_size, collate_fn=lambda x: list(zip(*x)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj78kzsAWgtQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVPbzTE18tAN"
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     for ii in train_ds: \n",
        "\n",
        "#         sentence_in = ii[0]\n",
        "#         target = ii[1]\n",
        "\n",
        "#         sentence_in = pad_sequence(sentence_in, batch_first=True, padding_value=word_to_ix[\"<UNK>\"])\n",
        "#         target = pad_sequence(target, batch_first=True, padding_value=-1)\n",
        "\n",
        "#         sentence_in = sentence_in.to(device)\n",
        "#         target = target.to(device)\n",
        "\n",
        "#         # Step 3. Run our forward pass.\n",
        "#         tag_scores = model(sentence_in)\n",
        "#         scores, one_hot_encod_class = get_flatten_tensor_to_calculate_loss(tag_scores, target)\n",
        "#         break\n",
        "# model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zu_IYiF9ff2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.eps :float = 1e-6 \n",
        "\n",
        "    def forward(self, scores, one_hot_encod_class):\n",
        "        intersection =torch.sum(scores * one_hot_encod_class)\n",
        "        union = torch.sum(scores + one_hot_encod_class)\n",
        "        \n",
        "        dice_loss = 1 - 2*intersection/(union + self.eps)\n",
        "        return dice_loss\n",
        "\n",
        "    def forward_2(self, scores, one_hot_encod_class):\n",
        "        p_y = torch.sum(scores*one_hot_encod_class )\n",
        "        lambda_ = 1\n",
        "\n",
        "        p_y_square = torch.sum(torch.square(scores))\n",
        "        y_square = torch.sum(one_hot_encod_class )\n",
        "\n",
        "        loss = 1 - (2*p_y + lambda_)/(p_y_square+ y_square +  lambda_)\n",
        "        return loss \n",
        "\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, scores, one_hot_encod_class):\n",
        "\n",
        "        return -torch.sum( one_hot_encod_class * torch.log(scores.view(-1,13)))/len(scores.view(-1,13))\n",
        "\n",
        "class JaccardCoefitient(nn.Module):\n",
        "    def __init__(self, eps = 1) -> None:\n",
        "        super(JaccardCoefitient, self).__init__()\n",
        "        self.eps = 1\n",
        "\n",
        "    def forward(self, scores, one_hot_encod_class, class_weight= None):\n",
        "        if torch.is_tensor(class_weight) == True:\n",
        "            intersection =torch.sum(torch.sum(scores * one_hot_encod_class) * class_weight) + self.eps\n",
        "            union = torch.sum(torch.sum(scores)*class_weight+ torch.sum(one_hot_encod_class)) - intersection  + self.eps  \n",
        "            return intersection/union  \n",
        "        else:\n",
        "            intersection =torch.sum(scores * one_hot_encod_class) + self.eps\n",
        "            union = torch.sum(scores)+ torch.sum(one_hot_encod_class) - intersection  + self.eps  \n",
        "            return intersection/union \n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha = 0.5, gamma = 2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma # From the paper , they sai dthat oit works best for them for gamma is 2\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, scores, one_hot_encod_class, class_weight= None):\n",
        "        modulating_factor = torch.pow((1- scores),  self.gamma)\n",
        "        log_scores = torch.log(scores)\n",
        "        # return torch.sum(-class_weights * modulating_factor * log_scores , dim =1)\n",
        "        return torch.mean(torch.sum(-self.alpha * modulating_factor * log_scores , dim =1))\n",
        "\n",
        "class TwerkyLoss(nn.Module):\n",
        "    def __init__(self, alpha = 0.5, beta= 0.7):\n",
        "        super(TwerkyLoss, self).__init__()\n",
        "        self.alpha =alpha\n",
        "        self.eps = 1e-6\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, scores , one_hot_encod_class):\n",
        "        \n",
        "        intersection = torch.sum(scores * one_hot_encod_class, 1)\n",
        "        fps = torch.sum(scores * (1. - one_hot_encod_class), 1)\n",
        "        fns = torch.sum((1. - scores) * one_hot_encod_class, 1)\n",
        "\n",
        "        numerator = intersection\n",
        "        denominator = intersection + self.alpha * fps + self.beta * fns\n",
        "        tversky_loss = numerator / (denominator + self.eps)\n",
        "\n",
        "        return torch.mean(1. - tversky_loss)\n",
        "\n",
        "diceloss = DiceLoss()\n",
        "crossentropyloss = CrossEntropyLoss()\n",
        "jaccardcoefitient = JaccardCoefitient()\n",
        "focalloss = FocalLoss()\n",
        "twerkyloss = TwerkyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C_of6Q2benA"
      },
      "outputs": [],
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), \n",
        "                   len(tag_to_ix), embedding_matrix, dense_layer_neurons).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# optimizer= optim.SGD(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 50], gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lossses_list =[]\n",
        "train_F1_score = []\n",
        "dev_F1_score = []\n",
        "count_epoch = 0"
      ],
      "metadata": {
        "id": "BYayzph9yUx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGFJNPGcRMm0",
        "outputId": "d5218e5d-6e62-4dbe-a9a2-23eba5071d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss is  398.92236328125 with f1 score, train 0.2364  dev 0.1999   at epoch  1\n",
            "Train Loss is  383.56781005859375 with f1 score, train 0.4301  dev 0.3490   at epoch  2\n",
            "Train Loss is  375.3397216796875 with f1 score, train 0.4872  dev 0.3616   at epoch  3\n",
            "Train Loss is  370.0382385253906 with f1 score, train 0.5681  dev 0.3912   at epoch  4\n",
            "Train Loss is  366.2223815917969 with f1 score, train 0.6039  dev 0.4010   at epoch  5\n",
            "Train Loss is  363.9497375488281 with f1 score, train 0.6159  dev 0.4139   at epoch  6\n",
            "Train Loss is  362.5957336425781 with f1 score, train 0.6294  dev 0.4074   at epoch  7\n",
            "Train Loss is  361.47515869140625 with f1 score, train 0.6465  dev 0.4235   at epoch  8\n",
            "Train Loss is  360.7033996582031 with f1 score, train 0.6580  dev 0.4348   at epoch  9\n",
            "Train Loss is  360.0280456542969 with f1 score, train 0.6676  dev 0.4300   at epoch  10\n",
            "Train Loss is  359.54669189453125 with f1 score, train 0.6753  dev 0.4263   at epoch  11\n",
            "Train Loss is  359.14501953125 with f1 score, train 0.6932  dev 0.4355   at epoch  12\n",
            "Train Loss is  358.8717346191406 with f1 score, train 0.7006  dev 0.4350   at epoch  13\n",
            "Train Loss is  358.6011047363281 with f1 score, train 0.6989  dev 0.4320   at epoch  14\n",
            "Train Loss is  358.3744812011719 with f1 score, train 0.7064  dev 0.4325   at epoch  15\n",
            "Train Loss is  358.12548828125 with f1 score, train 0.7164  dev 0.4383   at epoch  16\n",
            "Train Loss is  357.88641357421875 with f1 score, train 0.7234  dev 0.4397   at epoch  17\n",
            "Train Loss is  357.70648193359375 with f1 score, train 0.7360  dev 0.4499   at epoch  18\n",
            "Train Loss is  357.43212890625 with f1 score, train 0.7433  dev 0.4435   at epoch  19\n",
            "Train Loss is  357.4544372558594 with f1 score, train 0.7345  dev 0.4471   at epoch  20\n",
            "Train Loss is  357.3536376953125 with f1 score, train 0.7455  dev 0.4546   at epoch  21\n",
            "Train Loss is  357.3476867675781 with f1 score, train 0.7574  dev 0.4564   at epoch  22\n",
            "Train Loss is  357.1233825683594 with f1 score, train 0.7632  dev 0.4499   at epoch  23\n",
            "Train Loss is  357.0597229003906 with f1 score, train 0.7692  dev 0.4600   at epoch  24\n",
            "Train Loss is  357.0671081542969 with f1 score, train 0.7814  dev 0.4665   at epoch  25\n",
            "Train Loss is  356.94268798828125 with f1 score, train 0.7772  dev 0.4591   at epoch  26\n",
            "Train Loss is  356.82867431640625 with f1 score, train 0.7843  dev 0.4721   at epoch  27\n",
            "Train Loss is  356.8182373046875 with f1 score, train 0.7902  dev 0.4593   at epoch  28\n",
            "Train Loss is  356.7015075683594 with f1 score, train 0.7534  dev 0.4406   at epoch  29\n",
            "Train Loss is  356.6555480957031 with f1 score, train 0.7785  dev 0.4652   at epoch  30\n",
            "Train Loss is  356.6818542480469 with f1 score, train 0.8023  dev 0.4698   at epoch  31\n",
            "Train Loss is  356.5519714355469 with f1 score, train 0.8064  dev 0.4667   at epoch  32\n",
            "Train Loss is  356.5180358886719 with f1 score, train 0.7979  dev 0.4693   at epoch  33\n",
            "Train Loss is  356.4790344238281 with f1 score, train 0.7998  dev 0.4612   at epoch  34\n",
            "Train Loss is  356.35003662109375 with f1 score, train 0.8162  dev 0.4686   at epoch  35\n",
            "Train Loss is  356.4279479980469 with f1 score, train 0.8199  dev 0.4630   at epoch  36\n",
            "Train Loss is  356.3009948730469 with f1 score, train 0.8158  dev 0.4627   at epoch  37\n",
            "Train Loss is  356.4355773925781 with f1 score, train 0.8112  dev 0.4751   at epoch  38\n",
            "Train Loss is  356.3810119628906 with f1 score, train 0.8188  dev 0.4726   at epoch  39\n",
            "Train Loss is  356.2870788574219 with f1 score, train 0.8271  dev 0.4692   at epoch  40\n",
            "Train Loss is  356.2272644042969 with f1 score, train 0.8311  dev 0.4714   at epoch  41\n",
            "Train Loss is  356.2381286621094 with f1 score, train 0.8215  dev 0.4764   at epoch  42\n",
            "Train Loss is  356.2230224609375 with f1 score, train 0.8366  dev 0.4800   at epoch  43\n",
            "Train Loss is  356.1513977050781 with f1 score, train 0.8389  dev 0.4832   at epoch  44\n",
            "Train Loss is  356.2158203125 with f1 score, train 0.8305  dev 0.4685   at epoch  45\n",
            "Train Loss is  356.2955627441406 with f1 score, train 0.8248  dev 0.4811   at epoch  46\n",
            "Train Loss is  356.1949462890625 with f1 score, train 0.8424  dev 0.4714   at epoch  47\n",
            "Train Loss is  356.14849853515625 with f1 score, train 0.8392  dev 0.4832   at epoch  48\n",
            "Train Loss is  356.038330078125 with f1 score, train 0.8436  dev 0.4832   at epoch  49\n",
            "Train Loss is  356.22119140625 with f1 score, train 0.8442  dev 0.4745   at epoch  50\n",
            "Train Loss is  356.0650939941406 with f1 score, train 0.8417  dev 0.4757   at epoch  51\n",
            "Train Loss is  356.0450744628906 with f1 score, train 0.8402  dev 0.4612   at epoch  52\n",
            "Train Loss is  356.0648498535156 with f1 score, train 0.8428  dev 0.4739   at epoch  53\n",
            "Train Loss is  356.04168701171875 with f1 score, train 0.8482  dev 0.4707   at epoch  54\n",
            "Train Loss is  355.97637939453125 with f1 score, train 0.8507  dev 0.4749   at epoch  55\n",
            "Train Loss is  356.0223083496094 with f1 score, train 0.8490  dev 0.4632   at epoch  56\n",
            "Train Loss is  356.0423278808594 with f1 score, train 0.8393  dev 0.4676   at epoch  57\n",
            "Train Loss is  355.9933776855469 with f1 score, train 0.8481  dev 0.4664   at epoch  58\n",
            "Train Loss is  355.958984375 with f1 score, train 0.8487  dev 0.4687   at epoch  59\n",
            "Train Loss is  355.88671875 with f1 score, train 0.8487  dev 0.4701   at epoch  60\n",
            "Train Loss is  355.9801330566406 with f1 score, train 0.8482  dev 0.4725   at epoch  61\n",
            "Train Loss is  355.9911804199219 with f1 score, train 0.8505  dev 0.4700   at epoch  62\n",
            "Train Loss is  355.9053649902344 with f1 score, train 0.8491  dev 0.4639   at epoch  63\n",
            "Train Loss is  355.8012390136719 with f1 score, train 0.8569  dev 0.4633   at epoch  64\n",
            "Train Loss is  355.89508056640625 with f1 score, train 0.8566  dev 0.4593   at epoch  65\n",
            "Train Loss is  355.94354248046875 with f1 score, train 0.8574  dev 0.4651   at epoch  66\n",
            "Train Loss is  355.9033508300781 with f1 score, train 0.8585  dev 0.4531   at epoch  67\n",
            "Train Loss is  355.79486083984375 with f1 score, train 0.8574  dev 0.4623   at epoch  68\n",
            "Train Loss is  355.8419189453125 with f1 score, train 0.8506  dev 0.4569   at epoch  69\n",
            "Train Loss is  355.77972412109375 with f1 score, train 0.8561  dev 0.4613   at epoch  70\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score as AC\n",
        "\n",
        "unknown_word = \"<UNK>\"\n",
        "for epoch in range(epochs):  # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    loss_sum = 0\n",
        "    for ii in train_ds:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        sentence_in = ii[0]\n",
        "        target = ii[1]\n",
        "    \n",
        "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "        # Tensors of word indices.\n",
        "        # sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        # targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "\n",
        "        sentence_in = pad_sequence(sentence_in, batch_first=True, padding_value=word_to_ix[\"<UNK>\"])\n",
        "        target = pad_sequence(target, batch_first=True, padding_value=-1)\n",
        "        \n",
        "        \n",
        "        sentence_in =sentence_in.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        scores, one_hot_encod_class = get_flatten_tensor_to_calculate_loss(tag_scores, target)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        #  calling optimizer.step()\n",
        "        # loss = CustomLogLikelyhoodLoss(tag_scores, target, class_weights)\n",
        "\n",
        "        ## 1) Diceloss\n",
        "        # loss = diceloss.forward(scores, one_hot_encod_class)\n",
        "        # loss = diceloss.forward_2(scores, one_hot_encod_class)\n",
        "\n",
        "        ## 3) Cross entropy Loss\n",
        "        # loss = crossentropyloss(scores, one_hot_encod_class)\n",
        "\n",
        "        ## 4) Diceloss +  CrossentropyLoss\n",
        "        # loss = diceloss.forward(scores, one_hot_encod_class) + crossentropyloss.forward(scores, one_hot_encod_class)\n",
        "        # loss = diceloss.forward_2(scores, one_hot_encod_class) + crossentropyloss.forward(scores, one_hot_encod_class)\n",
        "\n",
        "        ## 3) JaccardCoefitient\n",
        "        # loss = jaccardcoefitient.forward(scores, one_hot_encod_class, class_weights)\n",
        "        # loss = jaccardcoefitient.forward(scores, one_hot_encod_class, class_weight=class_weights)\n",
        "\n",
        "        ## 4) Focal Loss\n",
        "        # loss = focalloss(scores, one_hot_encod_class)\n",
        "\n",
        "        ## 5) Twerky Lossù\n",
        "\n",
        "        loss = twerkyloss(scores, one_hot_encod_class) \n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_sum = loss_sum + loss\n",
        "        \n",
        "        # print(accuracy_score)\n",
        "    \n",
        "    d_f1_score = calculate_F1_Score(dev_ds)\n",
        "    t_f1_score = calculate_F1_Score(train_ds)\n",
        "    count_epoch +=1 \n",
        "    print(\"Train Loss is \", loss_sum.item(), f\"with f1 score, train {t_f1_score}  dev {d_f1_score} \",  \" at epoch \", count_epoch )\n",
        "    dev_F1_score.append(d_f1_score)\n",
        "    train_F1_score.append(t_f1_score)\n",
        "    Lossses_list.append(loss_sum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = np.array([i.detach().to(\"cpu\").item() for i in tqdm(Lossses_list)])\n",
        "NewMax =100\n",
        "NewMin = 0\n",
        "OldMax = max(loss_list)\n",
        "OldMin= min(loss_list)\n",
        "OldRange = (OldMax - OldMin)  \n",
        "NewRange = (NewMax - NewMin)  \n",
        "\n",
        "def getnew_value(OldValue):\n",
        "    NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
        "    return NewValue\n",
        "\n",
        "l_list = [getnew_value(i) for i in loss_list.tolist()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VHrdXVhqvcm",
        "outputId": "8ad25cd3-a1d6-42fe-8cea-2db216c00adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 32399.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "o0dOG1PCnx_T",
        "outputId": "1cb431b4-fb4a-4ba7-d81a-38236586aa3d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"6611cb43-72d6-49e4-a225-50c9dce6030f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6611cb43-72d6-49e4-a225-50c9dce6030f\")) {                    Plotly.newPlot(                        \"6611cb43-72d6-49e4-a225-50c9dce6030f\",                        [{\"mode\":\"lines+markers\",\"name\":\"Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69],\"y\":[100.0,65.0884273219081,46.317980080397234,35.52007918407747,30.25049447531195,26.609092676776697,20.248402627904564,16.461875372380018,13.973257233171825,12.161683364597666,10.971881375812009,9.781569180341624,9.100953462914493,8.0812770586698,8.010188260597701,7.249073266246823,6.836089299775339,6.212389972511198,5.927184435748255,5.611139739375088,5.237781825417477,5.141749589425343,4.669865095683595,4.386700385659564,4.196279912992753,3.9938412384190167,3.8279673762507858,3.52161660688745,3.313849106939888,3.125922978065081,3.2672502297347323,3.0643580381079043,2.8895272141411152,2.6119747776490922,2.5390152217329907,2.326315723833058,2.3080616624461237,2.1803399223692184,2.216791355511451,2.134818148165155,1.9450779510779816,1.6626502062652246,1.5300531578675856,1.5513117697312515,1.6125365718986095,1.3198480037596563,1.3157096606501961,1.1073752643862695,0.8915578367463326,0.9592452569202451,0.952839328545327,0.9862295215791917,0.769675128727981,0.856637023658284,0.6497765578169049,0.7052757071889822,0.569844177209521,0.5601502501996892,0.5966583729735583,0.26853878506182854,0.47216794189993033,0.3592988853117731,0.40107914382783133,0.2734140933825626,0.46326766973300887,0.39433307766309467,0.2554434801538103,0.057880113900807884,0.06853776464845909,0.0],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"train_F1_score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69],\"y\":[15.049999999999999,34.1,46.0,49.35,53.169999999999995,56.28999999999999,61.23,60.39,62.849999999999994,64.47,66.24,65.64999999999999,67.23,66.60000000000001,67.28,67.74,69.26,69.42,68.57,69.99,71.25,72.39,72.53,72.86,72.19,72.46000000000001,73.75,73.54,73.92999999999999,75.92999999999999,74.11,75.03999999999999,75.72,75.47,76.06,76.22,76.19,76.39,76.77000000000001,77.46,77.60000000000001,78.0,77.72,79.06,75.7,78.21000000000001,78.28,79.62,79.49000000000001,78.81,79.7,78.60000000000001,80.11,80.28999999999999,80.24,80.58,80.51,80.71000000000001,81.28,81.34,81.69999999999999,80.83,79.93,80.65,79.09,82.12,82.08,81.78999999999999,82.17,82.57],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"dev_F1_score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69],\"y\":[13.59,29.330000000000002,37.51,38.87,40.57,41.620000000000005,44.0,43.43,43.86,44.43,45.71,44.95,46.160000000000004,44.800000000000004,45.69,46.42,46.86,47.04,46.089999999999996,46.46,47.15,47.78,48.24,48.199999999999996,47.64,47.620000000000005,47.89,47.79,48.02,48.86,47.25,48.480000000000004,48.41,48.44,49.02,48.559999999999995,48.92,48.949999999999996,48.78,48.809999999999995,49.04,49.33,49.05,50.1,46.61,49.08,49.74,50.71,50.14999999999999,49.26,49.97,49.97,51.43,51.07000000000001,50.3,50.870000000000005,49.76,50.51,50.72,51.11,50.62,49.53,49.28,49.41,48.809999999999995,50.94,50.49,49.89,50.77,50.949999999999996],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"family\":\"Courier New, monospace\",\"color\":\"RebeccaPurple\"},\"title\":{\"text\":\"Twerky Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss F1 Score\"}},\"legend\":{\"title\":{\"text\":\"Legend Title\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6611cb43-72d6-49e4-a225-50c9dce6030f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "\n",
        "# l = [i.detach().to(\"cpu\").item() for i in tqdm(Lossses_list)]\n",
        "\n",
        "train_F1_score_ = [float(i)*100 for i in train_F1_score]\n",
        "dev_F1_score_ = [float(i)*100 for i in dev_F1_score]\n",
        "fig.add_trace(go.Scatter(x=np.arange(0, len(Lossses_list)), y=l_list,\n",
        "                    mode='lines+markers',\n",
        "                    name='Loss'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(0, len(Lossses_list)), y=train_F1_score_ ,\n",
        "                    mode='lines+markers',\n",
        "                    name='train_F1_score'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(0, len(Lossses_list)), y=dev_F1_score_,\n",
        "                    mode='lines+markers',\n",
        "                    name='dev_F1_score'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Twerky Loss\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss F1 Score\",\n",
        "    legend_title=\"Legend Title\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(loss_list), max(train_F1_score_), max(dev_F1_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Z7tHIdVRfr",
        "outputId": "e2459408-892c-4464-c4d2-a5a961f1c6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356.08160400390625, 82.57, 51.43)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "\n",
        "# l = [i.detach().to(\"cpu\").item() for i in tqdm(Lossses_list)]\n",
        "\n",
        "# train_F1_score_ = [float(i)*100 for i in train_F1_score]\n",
        "# dev_F1_score_ = [float(i)*100 for i in dev_F1_score]\n",
        "fig.add_trace(go.Scatter(x=np.arange(0, len(Lossses_list)), y=loss_list,\n",
        "                    mode='lines+markers',\n",
        "                    name='Loss'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Twerky Loss\",\n",
        "    xaxis_title=\"Epochs\",\n",
        "    yaxis_title=\"Loss\",\n",
        "    legend_title=\"Legend Title\",\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "\n",
        "        color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "mBgmcwY_tMVY",
        "outputId": "19164a12-cb25-4dc7-869f-838a87bc1096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"18afc809-8890-4ce2-b50f-464a399b9e12\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"18afc809-8890-4ce2-b50f-464a399b9e12\")) {                    Plotly.newPlot(                        \"18afc809-8890-4ce2-b50f-464a399b9e12\",                        [{\"mode\":\"lines+markers\",\"name\":\"Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69],\"y\":[409.9143371582031,391.1204833984375,381.0158386230469,375.2030334472656,372.36627197265625,370.406005859375,366.98187255859375,364.9434814453125,363.6037902832031,362.6285705566406,361.9880676269531,361.3472900390625,360.98089599609375,360.4319763183594,360.3937072753906,359.9839782714844,359.76165771484375,359.4259033203125,359.2723693847656,359.10223388671875,358.9012451171875,358.84954833984375,358.59552001953125,358.4430847167969,358.340576171875,358.2315979003906,358.1423034667969,357.9773864746094,357.86553955078125,357.7643737792969,357.8404541015625,357.7312316894531,357.6371154785156,357.4877014160156,357.44842529296875,357.33392333984375,357.3240966796875,357.2553405761719,357.27496337890625,357.2308349609375,357.1286926269531,356.9766540527344,356.9052734375,356.9167175292969,356.9496765136719,356.7921142578125,356.7898864746094,356.677734375,356.5615539550781,356.5979919433594,356.59454345703125,356.6125183105469,356.4959411621094,356.5427551269531,356.431396484375,356.4612731933594,356.38836669921875,356.3831481933594,356.4028015136719,356.2261657714844,356.3357849121094,356.2750244140625,356.2975158691406,356.2287902832031,356.33099365234375,356.29388427734375,356.2191162109375,356.1127624511719,356.1184997558594,356.08160400390625],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"font\":{\"family\":\"Courier New, monospace\",\"color\":\"RebeccaPurple\"},\"title\":{\"text\":\"Twerky Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"legend\":{\"title\":{\"text\":\"Legend Title\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('18afc809-8890-4ce2-b50f-464a399b9e12');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi1g0AI3nx76"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Sem_4/NLP_HW_1/nlp2022-hw1-main/Twerky_1.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/Sem_4/NLP_HW_1/nlp2022-hw1-main/model_33.pt\")"
      ],
      "metadata": {
        "id": "vZGQHnkcyEmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4hpR95gccna"
      },
      "source": [
        "### References  \n",
        "1. [Pytorch Sequence model tutorial](#https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)  \n",
        "2. https://arxiv.org/pdf/1911.02855.pdf  \n",
        "3. [Focal Loss Paper](#https://arxiv.org/pdf/1708.02002.pdf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "r6wJnYTMSAg5"
      ],
      "name": "HW1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}